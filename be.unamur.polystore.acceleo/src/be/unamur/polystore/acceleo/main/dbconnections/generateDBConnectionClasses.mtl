[comment encoding = UTF-8 /]
[module generateDBConnectionClasses('http://www.unamur.be/polystore/Pml')]
[import be::unamur::polystore::acceleo::main::util /]

[template public generateDBConnectionClasses(conceptualSchema: ConceptualSchema)]
[generateDBConnectionInterface()/]
[generateDBCredentials(conceptualSchema)/]
[generateDBConnectionMgr(conceptualSchema)/]
[generateSparkConnectionMgr(conceptualSchema) /]
[generateRelationalDBConnectionClasses(conceptualSchema) /]
[generateDatabaseTypeConverters()/]
[comment][generateDocumentDBConnectionClasses(conceptualSchema) /]
[generateKeyValueDBConnectionClasses(conceptualSchema) /]
[generateColumnDBConnectionClasses(conceptualSchema) /]
[generateGraphDBConnectionClasses(conceptualSchema) /][/comment]
[/template]

[template public generateDBConnectionInterface()]
[file ('src/main/java/dbconnection/DBConnection.java', false, 'UTF-8')]
package dbconnection;

public interface DBConnection {
	int insertOrUpdateOrDelete(String query, java.util.List<Object> inputs);
}
[/file]
[/template]

[template public generateDBConnectionMgr(conceptualSchema: ConceptualSchema)]
[file ('src/main/java/dbconnection/DBConnectionMgr.java', false, 'UTF-8')]
package dbconnection;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.ResultSetMetaData;
import java.sql.SQLException;
import java.util.*;
import java.util.Map.Entry;

import org.bson.Document;
import org.bson.conversions.Bson;
import com.mongodb.MongoClientSettings;
import com.mongodb.ServerAddress;
import com.mongodb.client.MongoClient;
import com.mongodb.client.MongoClients;
import com.mongodb.client.MongoCollection;
import com.mongodb.client.MongoDatabase;
import com.mongodb.client.model.UpdateOptions;
import com.mongodb.client.model.UpdateManyModel;
import redis.clients.jedis.Jedis;
import com.datastax.oss.driver.api.core.CqlSession;
import java.net.InetSocketAddress;
import com.datastax.oss.driver.api.core.CqlIdentifier;
import com.datastax.oss.driver.api.core.cql.BatchStatement;
import com.datastax.oss.driver.api.core.cql.BoundStatement;
import com.datastax.oss.driver.api.core.cql.BatchType;
import com.datastax.oss.driver.api.core.metadata.schema.ColumnMetadata;
import com.datastax.oss.driver.api.core.type.DataType;

import util.CassandraTypeConverter;
import util.SQLTypeConverter;

public class DBConnectionMgr {

	[instantiateLogger('DBConnectionMgr') /]
	private static Map<String, DBConnection> mapDB = new HashMap<String, DBConnection>(); 
	private static Map<String, MongoClient> mapMongoConnection = new HashMap<>();
	private static Map<String, Connection> mapJDBCConnection = new HashMap<>();
	private static Map<String, CqlSession> mapCassandraSession = new HashMap<>();
	
	public static Map<String, DBConnection> getMapDB(){
		return mapDB;
	}

	public static void update(Bson filter, Bson updateOp, String struct, String db){
		DBCredentials credentials = DBCredentials.getDbPorts().get(db);
		if(credentials.getDbType().equals("mongodb")){ 
			MongoDatabase mongoDatabase = getMongoClient(credentials).getDatabase(db);
	        MongoCollection<Document> structCollection = mongoDatabase.getCollection(struct);
	        structCollection.updateMany(filter, updateOp);
			logger.info("Update many on collection ['['/]{}[']'/], filter ['['/]{}[']'/]",db+ " - "+struct, filter);
		}
		else{
			logger.error("Can't perform update, wrong database type, need document db. Database : '{}' , type : '{}' ",credentials.getDbName(), credentials.getDbType());
			throw new RuntimeException("Can't perform update, wrong database type, need document db");
		}
	}

	public static void bulkUpdatesInMongoDB(List<UpdateManyModel<Document>> updates, String struct, String db) {
		if(updates == null || updates.size() == 0)
			return;
		DBCredentials credentials = DBCredentials.getDbPorts().get(db);
		if(credentials.getDbType().equals("mongodb")){ 
			MongoDatabase mongoDatabase = DBConnectionMgr.getMongoClient(credentials).getDatabase(db);
	        MongoCollection<Document> structCollection = mongoDatabase.getCollection(struct);
	        structCollection.bulkWrite(updates);
			logger.info("Update bulk many on collection ['['/]{}[']'/]",db+ " - "+struct);
		}
		else{
			logger.error("Can't perform update, wrong database type, need document db. Database : '{}' , type : '{}' ",credentials.getDbName(), credentials.getDbType());
			throw new RuntimeException("Can't perform update, wrong database type, need document db");
		}
	}

	public static void upsertMany(Bson filter, Bson updateOp, String struct, String db){
		upsertMany(filter, updateOp, true, struct, db);
	}

	public static void upsertMany(Bson filter, Bson updateOp, boolean upsert, String struct, String db){
		DBCredentials credentials = DBCredentials.getDbPorts().get(db);
		if(credentials.getDbType().equals("mongodb")){ 
			MongoDatabase mongoDatabase = DBConnectionMgr.getMongoClient(credentials).getDatabase(db);
	        MongoCollection<Document> structCollection = mongoDatabase.getCollection(struct);
			UpdateOptions options = new UpdateOptions().upsert(upsert);
	        structCollection.updateMany(filter, updateOp, options);
			logger.info("Update many on collection ['['/]{}[']'/], filter ['['/]{}[']'/]",db+ " - "+struct, filter);
		}
		else{
			logger.error("Can't perform update, wrong database type, need document db. Database : '{}' , type : '{}' ",credentials.getDbName(), credentials.getDbType());
			throw new RuntimeException("Can't perform update, wrong database type, need document db");
		}
	}

	public static void upsertMany(Bson filter, Bson updateOp, List<Bson> arrayFiltersConditions, String struct, String db){
		DBCredentials credentials = DBCredentials.getDbPorts().get(db);
		if(credentials.getDbType().equals("mongodb")){ 
			MongoDatabase mongoDatabase = DBConnectionMgr.getMongoClient(credentials).getDatabase(db);
	        MongoCollection<Document> structCollection = mongoDatabase.getCollection(struct);
			UpdateOptions updateOptions = new UpdateOptions().arrayFilters(arrayFiltersConditions);
	        structCollection.updateMany(filter, updateOp, updateOptions);
			logger.info("Update many on collection ['['/]{}[']'/], filter ['['/]{}[']'/]",db+ " - "+struct, filter);
		}
		else{
			logger.error("Can't perform update, wrong database type, need document db. Database : '{}' , type : '{}' ",credentials.getDbName(), credentials.getDbType());
			throw new RuntimeException("Can't perform update, wrong database type, need document db");
		}
	}


	public static void insertMany(List<Document> documents, String struct, String db) {
		DBCredentials credentials = DBCredentials.getDbPorts().get(db);
		if(!credentials.getDbType().equals("mongodb")){
			logger.error("Can't perform update, wrong database type, need document db. Database : '{}' , type : '{}' ",credentials.getDbName(), credentials.getDbType());
			throw new RuntimeException("Can't perform update, wrong database type, need document db");
		}
		else{
			MongoDatabase mongoDatabase = getMongoClient(credentials).getDatabase(db);
			MongoCollection<Document> structCollection = mongoDatabase.getCollection(struct);
			structCollection.insertMany(documents);
			logger.info("Insert many on collection ['['/]{}[']'/],  ['['/]{}[']'/] documents",db+ " - "+struct, documents.size());
		}
	}

	public static MongoClient getMongoClient(DBCredentials credentials) {
		MongoClient mongoClient = null;
		mongoClient = mapMongoConnection.get(credentials.getUrl()+credentials.getPort());
		if (mongoClient == null) {
			mongoClient = MongoClients.create(
					MongoClientSettings.builder()
							.applyToClusterSettings(builder ->
									builder.hosts(Arrays.asList(new ServerAddress(credentials.getUrl(), credentials.getPort()))))
							.build());
			mapMongoConnection.put(credentials.getUrl()+credentials.getPort(), mongoClient);
		}
		return mongoClient;
	}

	public static void insertInTable(List<String> columns, List<List<Object>> rows, String struct, String db) {
		DBCredentials credentials = DBCredentials.getDbPorts().get(db);
		if((credentials.getDbType().equals("mariadb") || credentials.getDbType().equals("sqlite") || credentials.getDbType().equals("postgresql") || credentials.getDbType().equals("mysql") )){
			PreparedStatement statement = null;
			try {
				String sql = "INSERT INTO " + struct + "("+String.join(",",columns)+") VALUES ("+String.join(",", Collections.nCopies(columns.size(),"?"))+")";
				Connection conn = getJDBCConnection(credentials);
				// Map<String, String> columnTypes = getSQLColumns(conn, struct);
				statement = conn.prepareStatement(sql);
				for (List<Object> row : rows) {
					for (int i = 1; i <= row.size(); i++) {
						// statement.setObject(i, SQLTypeConverter.get(row.get(i-1), columnTypes.get(columns.get(i-1))));
						statement.setObject(i, row.get(i-1));
					}
					statement.addBatch();
					statement.clearParameters();
				}
				int['['/][']'/] result = statement.executeBatch();
				logger.info("BATCH INSERT INTO '{}' - '{}' lines ", struct, result.length);  
			} catch (SQLException e) {
				logger.error("SQL Error in preparedStatement");
				e.printStackTrace();
				throw new RuntimeException("Error in insert SQL statement");
			} finally {
				if(statement != null) {
					try {
						statement.close();
					} catch(SQLException e2) {}
				}
			}
		} else
			if(credentials.getDbType().equals("cassandra")) {
				CqlSession session = getCassandraConnection(credentials);
				Map<String, DataType> schema = getCassandraColumns(session, db, struct);
				List<DataType> columnTypes = new ArrayList<DataType>();
				for(String colName : columns)
					columnTypes.add(schema.get(colName));
				
				String cql = "INSERT INTO " + struct + "("+String.join(",",columns)+") VALUES ("+String.join(",", Collections.nCopies(columns.size(),"?"))+")";
				
				com.datastax.oss.driver.api.core.cql.PreparedStatement statement = getCassandraConnection(credentials).prepare(cql);
				
				BoundStatement['['/][']'/] bounds = new BoundStatement['['/]rows.size()[']'/];
				int counter = 0;
				for (List<Object> row : rows) {
					Object['['/][']'/] cqlRow = new Object['['/]row.size()[']'/];
					for(int i = 0; i < row.size(); i++)
						cqlRow['['/]i[']'/] = (CassandraTypeConverter.get(row.get(i), columnTypes.get(i)));
					
					bounds['['/]counter[']'/] = statement.bind(cqlRow);
					counter++;
				}
				
				BatchStatement batchStmt = BatchStatement.newInstance(BatchType.LOGGED, bounds);
				session.execute(batchStmt);
			}
			else{
				logger.error("Can't perform update, wrong database type, need relational (mariadb or sqlite or postgresql or mysql) or cassandra database. Database : '{}' , type : '{}' ",credentials.getDbName(), credentials.getDbType());
				throw new RuntimeException("Can't perform update, wrong database type, need document db");
			}
	}

	private static Map<String, DataType> getCassandraColumns(CqlSession session, String db, String table) {
		Map<String, DataType> res = new HashMap<String, DataType>();
		for(Entry<CqlIdentifier, ColumnMetadata> entry : session.getMetadata().getKeyspace(db).get().getTable(table).get().getColumns().entrySet()) {
			String colName = entry.getKey().asCql(true);
			DataType colType = entry.getValue().getType();
			res.put(colName, colType);
		}
		
		return res;
	}

	private static Map<String, String> getSQLColumns(Connection conn, String table) {
		Map<String, String> res = new HashMap<String, String>();
		PreparedStatement ps = null;
		ResultSet rs = null;
		try {
			ps = conn.prepareStatement("select * from " + table + " LIMIT 0");
			rs = ps.executeQuery();
			ResultSetMetaData rsm = rs.getMetaData();
			for (int i = 1; i <= rsm.getColumnCount(); i++) {
				String colName = rsm.getColumnLabel(i);
				String colType = rsm.getColumnClassName(i);
				res.put(colName, colType);
			}

		} catch (SQLException e) {
			e.printStackTrace();
		} finally {
			try {
				if (rs != null)
					rs.close();
			} catch (SQLException e) {
			}
			try {
				if (ps != null)
					ps.close();
			} catch (SQLException e) {
			}
		}

		return res;
	}

	public static void updatesInTable(List<String> updates, String db) {
		if(updates == null || updates.size() == 0)
			return;

		DBCredentials credentials = DBCredentials.getDbPorts().get(db);
		java.sql.Statement stmt = null;
		try {
			stmt = getJDBCConnection(credentials).createStatement();
			
			for(int i = 0; i < updates.size(); i++) {
				stmt.addBatch(updates.get(i));
				if(i % 1000 == 0) {
					stmt.executeBatch();
				}

			}

			stmt.executeBatch();
		} catch (SQLException e) {
			e.printStackTrace();
			logger.error("SQL Error in update Query");
		} finally {
			if(stmt != null)
				try {
					stmt.close();
				} catch (SQLException e2) {
					e2.printStackTrace();
				}
		}
	}

	public static void updateInTable(String updateSQL, String db) {
		DBCredentials credentials = DBCredentials.getDbPorts().get(db);
		java.sql.Statement stmt = null;
		try {
			stmt = getJDBCConnection(credentials).createStatement();
			int count = stmt.executeUpdate(updateSQL);
			logger.debug("SQL query :" + updateSQL + " => " + count + " rows updated.");
		} catch (SQLException e) {
			e.printStackTrace();
			logger.error("SQL Error in update Query");
		} finally {
			if(stmt != null)
				try {
					stmt.close();
				} catch (SQLException e2) {
					e2.printStackTrace();
				}
		}
	}

	public static void updateInTable(String filtercolumn, Object filtervalue, List<String> columns, List<Object> values, String struct, String db) {
		DBCredentials credentials = DBCredentials.getDbPorts().get(db);
		if((credentials.getDbType().equals("mariadb") || credentials.getDbType().equals("sqlite") || credentials.getDbType().equals("postgresql") || credentials.getDbType().equals("mysql"))){
			try {
				StringJoiner joiner = new StringJoiner(",", "", "= ?");
				for (String s : columns) {
					joiner.add(s);
				}
				String sql = "UPDATE " + struct + " SET " + joiner +" WHERE "+filtercolumn +"= ?";
				PreparedStatement statement = getJDBCConnection(credentials).prepareStatement(sql);
				for (int i = 1; i <= values.size(); i++) {
					statement.setObject(i,values.get(i-1));
				}
				statement.setObject(values.size()+1,filtervalue);
				statement.addBatch();
				int['['/][']'/] result = statement.executeBatch();
				logger.info("BATCH UPDATE INTO '{}' - '{}' lines ", struct, result.length);  
			} catch (SQLException e) {
				e.printStackTrace();
				logger.error("SQL Error in preparedStatement");
			}
		}
		else{
			logger.error("Can't perform update, wrong database type, need relational (mariadb or sqlite or postgresql) database. Database : '{}' , type : '{}' ",credentials.getDbName(), credentials.getDbType());
			throw new RuntimeException("Can't perform update, wrong database type, need document db");
		}
	}

	public static void writeKeyValueList(String key, String value, String dbName) {
		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		logger.debug("Jedis LPush key ['['/]{}[']'/] value ['['/]{}[']'/] to redis db ['['/]{}[']'/]", key, value, dbName);
		Jedis jedis;
		jedis = new Jedis(credentials.getUrl(), credentials.getPort());
		jedis.lpush(key, value);
		jedis.close();
	}

	public static Connection getJDBCConnection(DBCredentials credentials) {
		Connection res = mapJDBCConnection.get(credentials.getUrl() + credentials.getPort());
		try {
			if (res == null) {
				res = DriverManager.getConnection("jdbc:"+credentials.getDbTypeForJDBCConnection()+"://" + credentials.getUrl() + ":" + credentials.getPort() + "/" + credentials.getDbName(), credentials.getUserName(), credentials.getUserPwd());
				mapJDBCConnection.put(credentials.getUrl() + credentials.getPort(), res);
			}
		} catch (SQLException e) {
			e.printStackTrace();
			logger.error("Immpossible to connect to relational db ['['/]{} - {} : {}[']'/] ", credentials.getDbName(), credentials.getUrl(),credentials.getPort());
		}
		return res;
	}

	public static CqlSession getCassandraConnection(DBCredentials credentials) {
		CqlSession res = mapCassandraSession.get(credentials.getUrl() + credentials.getDbName() + credentials.getPort());
		
			if (res == null) {
				res = CqlSession
                		.builder()
                   		.addContactPoint(new InetSocketAddress(credentials.getUrl(), credentials.getPort()))
                    	.withLocalDatacenter("datacenter1")
                    	.withKeyspace(credentials.getDbName())
                    	.build();
				mapCassandraSession.put(credentials.getUrl() + credentials.getDbName() + credentials.getPort(), res);
			}
		
		return res;
	}

}


[/file]
[/template]

[template public generateSparkConnectionMgr(conceptualSchema: ConceptualSchema)]
[file ('src/main/java/dbconnection/SparkConnectionMgr.java', false, 'UTF-8')]
package dbconnection;

import static java.util.Collections.singletonList;

import java.util.*;

import com.redislabs.provider.redis.ReadWriteConfig;
import com.redislabs.provider.redis.RedisConfig;
import com.redislabs.provider.redis.RedisContext;
import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.rdd.RDD;
import org.apache.spark.sql.*;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;
import org.bson.Document;
import redis.clients.jedis.Jedis;
import redis.clients.jedis.exceptions.JedisDataException;
import redis.clients.jedis.ScanParams;
import redis.clients.jedis.ScanResult;

import org.apache.commons.lang3.StringUtils;

import com.mongodb.spark.MongoSpark;
import com.mongodb.spark.config.ReadConfig;
import scala.Tuple2;

import com.mongodb.client.MongoClient;
import com.mongodb.client.MongoClients;
import com.mongodb.client.MongoCollection;
import com.mongodb.client.MongoCursor;
import com.mongodb.client.MongoDatabase;

import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.ResultSet;
import java.sql.ResultSetMetaData;
import java.sql.SQLException;
import java.sql.Statement;

import com.datastax.oss.driver.api.core.CqlSession;

[generateImportDataset(conceptualSchema)/]
[generateImportRow(conceptualSchema)/]

public class SparkConnectionMgr {
	[instantiateLogger('SparkConnectionMgr') /]
	private static SparkSession session = null;

		private static SparkSession getSession() {
		if (session == null) {
			session = SparkSession.builder().appName("Polystore").config("spark.master", "local")
					.config("spark.sql.shuffle.partitions", 5)
					.config("spark.some.config.option", "some-value")
					.config("spark.mongodb.input.uri", "mongodb://127.0.0.1:1/fakedb.fakecollection")
//			.config("spark.mongodb.output.uri", "mongodb://127.0.0.1:1/mymongo.productCollection")
					.getOrCreate();
			// session.sparkContext().setLogLevel("ERROR");
		}
		return session;
	}

	public static Dataset<Row> getDatasetFromMongoDB(String dbName, String collectionName, String bsonQuery) {
		Map<String, String> readOverrides = new HashMap<String, String>();
		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		logger.debug("Mongo find on db ['['/]{}[']'/], collection ['['/]{}[']'/], bsonquery : ['['/]{}[']'/]",dbName, collectionName, bsonQuery);
		[if (isSparkConfiguration())]	
		// https://docs.mongodb.com/manual/core/read-preference/#replica-set-read-preference-modes
		
		
		String mongoURL = "mongodb://" + credentials.getUrl() + ":" + credentials.getPort() + "/" + dbName + "." + collectionName;
		getSession().sparkContext().conf().set("spark.mongodb.input.uri", mongoURL);
		getSession().sparkContext().conf().set("spark.mongodb.output.uri", mongoURL);
		
//		readOverrides.put("uri", "mongodb://" + credentials.getUrl() + ":" + credentials.getPort());
		readOverrides.put("database", dbName);
		readOverrides.put("collection", collectionName);
		readOverrides.put("readPreference.name", "primaryPreferred");
		
		JavaSparkContext jsc = new JavaSparkContext(getSession().sparkContext());
		
		ReadConfig readConfig = ReadConfig.create(jsc).withOptions(readOverrides);

		Dataset<Row> res = (bsonQuery != null)
				? MongoSpark.load(jsc, readConfig).withPipeline(singletonList(Document.parse(bsonQuery))).toDF()
				: MongoSpark.load(jsc, readConfig).toDF();
		return res;
		[else]
		MongoDatabase database = DBConnectionMgr.getMongoClient(credentials).getDatabase(dbName);
		MongoCollection<Document> collection = database.getCollection(collectionName);
		MongoCursor<Document> cursor = null;
		if (bsonQuery != null) {
			Document query = Document.parse(bsonQuery);
			cursor = collection.aggregate(Arrays.asList(query)).cursor();
		} else
			cursor = collection.find().cursor();

		Dataset<Row> res = new Dataset<Row>();
		while (cursor.hasNext()) {
			Document doc = cursor.next();
			res.add(new Row(doc));
		}
		cursor.close();
		return res;
		[/if]

	}

	public static Dataset<Row> getCassandraDataset(String dbName, String physicalStructName, String where) {
		[if (isSparkConfiguration(conceptualSchema))]
		//TODO Spark for Cassandra
		[else]
		Dataset<Row> res = new Dataset<Row>();
		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		CqlSession session = DBConnectionMgr.getCassandraConnection(credentials);
		String query = "SELECT * FROM " + physicalStructName;
		if (where != null) {
			query += " WHERE " + where + " ALLOW FILTERING";
		}

		try {
			com.datastax.oss.driver.api.core.cql.ResultSet rs = session.execute(query);
			java.util.Iterator<com.datastax.oss.driver.api.core.cql.Row> it = rs.iterator();
			while (it.hasNext()) {
				com.datastax.oss.driver.api.core.cql.Row row = it.next();
				Map<String, Object> fieldValues = new HashMap<String, Object>();
				for(int i = 0; i < row.getColumnDefinitions().size(); i++) {
					String colName = row.getColumnDefinitions().get(i).getName().asCql(true);
					Object value = row.getObject(colName);
					fieldValues.put(colName, value);
				}
				res.add(new Row(fieldValues));
			}
		} catch (Exception e) {
			logger.debug("Impossible to execute query on db ['['/]{}[']'/], keyspace ['['/]{}[']'/], query : ['['/]{}[']'/]", dbName,
					physicalStructName, query);
			e.printStackTrace();
		}

		return res;
		[/if]
	}

	public static Dataset<Row> getDataset(String dbName, String physicalStructName, String where) {
		[if (isSparkConfiguration(conceptualSchema))]
		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		DataFrameReader dfr = getSession().sqlContext().read().format("jdbc")
				.option("url", "jdbc:"+credentials.getDbType()+"://" + credentials.getUrl() + ":" + credentials.getPort() + "/" + credentials.getDbName())
				.option("user", credentials.getUserName()).option("password", credentials.getUserPwd());

		Dataset<Row> d = dfr.option("dbtable", physicalStructName).load();
		logger.debug("Spark SQL data retrieval : ['['/]{}[']'/]['['/]{}[']'/] ", physicalStructName, where);
		if(where != null) {
			d = d.where(where);
		}
		return d;
		[else]
		Dataset<Row> res = new Dataset<Row>();

		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		DataFrameReader dfr = getSession().sqlContext().read().format("jdbc")
				.option("url", "jdbc:"+credentials.getDbType()+"://" + credentials.getUrl() + ":" + credentials.getPort() + "/" + credentials.getDbName())
				.option("user", credentials.getUserName()).option("password", credentials.getUserPwd());

		String query = "SELECT * FROM " + physicalStructName;
		if (where != null) {
			query += " WHERE " + where;
		}
		Connection conn = DBConnectionMgr.getJDBCConnection(credentials);
		Statement stmt = null;
		ResultSet rs = null;
		try {
			stmt = conn.createStatement();
			logger.debug("SQL query : {}",query);
			rs = stmt.executeQuery(query);
			ResultSetMetaData rsmd = rs.getMetaData();
			while (rs.next()) {
				Map<String, Object> fieldValues = new HashMap<String, Object>();
				for (int i = 0; i < rsmd.getColumnCount(); i++) {
					String colName = rsmd.getColumnName(i + 1);
					Object value = rs.getObject(colName);
					fieldValues.put(colName, value);
				}

				res.add(new Row(fieldValues));
			}
		} catch (SQLException e) {
			e.printStackTrace();
		} finally {
			if (rs != null)
				try {
					rs.close();
				} catch (SQLException e) {
					e.printStackTrace();
				}
			if (stmt != null)
				try {
					stmt.close();
				} catch (SQLException e) {
					e.printStackTrace();
				}
		}

		return res;
		[/if]
	}

/**	public static void writeDataset(List<Row> rows, StructType structType, String formattype, String physicalStructName, String dbName){
		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		Dataset<Row> data = getSession().createDataFrame(rows, structType);
		String mongoURL = "mongodb://" + credentials.getUrl() + ":" + credentials.getPort() + "/" + dbName + "." + physicalStructName;
		
		if(formattype.equals("mongo")){
			data.write()
                .format("mongo")
                .option("spark.mongodb.output.uri", mongoURL)
                .option("collection",physicalStructName)
                .mode(SaveMode.Append)
                .save();
		}else if(formattype.equals("jdbc"))
			{
			data.write()
				.format(formattype)
				.option("url", "jdbc:"+credentials.getDbType()+"://" + credentials.getUrl() + ":" + credentials.getPort() + "/" + credentials.getDbName())
				.option("dbtable",physicalStructName)
				.option("user", credentials.getUserName()).option("password", credentials.getUserPwd())
				.mode(SaveMode.Append)
				.save();
			}
	}
**/

	public static void writeKeyValue(String key, String value, String dbName){
		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		SparkConf sparkConf = new SparkConf()
                .setAppName("Polystore")
                .setMaster("local['['/]*[']'/]")
                .set("spark.redis.host", credentials.getUrl())
                .set("spark.redis.port", String.valueOf(credentials.getPort()));
        RedisConfig redisConfig = RedisConfig.fromSparkConf(sparkConf);
        ReadWriteConfig readWriteConfig = ReadWriteConfig.fromSparkConf(sparkConf);
		//        JavaSparkContext jsc = new JavaSparkContext(sparkConf);
        JavaSparkContext jsc = JavaSparkContext.fromSparkContext(getSession().sparkContext());
        RedisContext redisContext = new RedisContext(jsc.sc());

		List<Tuple2<String, String>> data = Arrays.asList(new Tuple2<String, String>(key,value));
		RDD<Tuple2<String, String>> items = jsc.parallelize(data,1).rdd();
        redisContext.toRedisKV(items, 0, redisConfig, readWriteConfig);
	}

	public static void writeKeyValueHash(String key, List<Tuple2<String, String>> hash, String dbName){
		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		SparkConf sparkConf = new SparkConf()
                .setAppName("Polystore")
                .setMaster("local['['/]*[']'/]")
                .set("spark.redis.host", credentials.getUrl())
                .set("spark.redis.port", String.valueOf(credentials.getPort()));
        RedisConfig redisConfig = RedisConfig.fromSparkConf(sparkConf);
        ReadWriteConfig readWriteConfig = ReadWriteConfig.fromSparkConf(sparkConf);
		//        JavaSparkContext jsc = new JavaSparkContext(sparkConf);
        JavaSparkContext jsc = JavaSparkContext.fromSparkContext(getSession().sparkContext());
        RedisContext redisContext = new RedisContext(jsc.sc());

		RDD<Tuple2<String, String>> items = jsc.parallelize(hash,1).rdd();
		redisContext.toRedisHASH(items, key,0, redisConfig, readWriteConfig);
	}

	public static Dataset<Row> getRowsFromKeyValue(String dbName, String keypattern) {
		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		logger.debug("Get keypattern (string value) ['['/]{}[']'/] from redis db ['['/]{}[']'/]", keypattern, dbName);
 		int countInKeyPattern = StringUtils.countMatches(keypattern,':'); // According to Redis naming convention. Semi-colon should be used as separator. 
        int countInKey;
		[if (isSparkConfiguration())]
		SparkConf sparkConf = new SparkConf()
                .setAppName("Polystore")
                .setMaster("local['['/]*[']'/]")
                .set("spark.redis.host", credentials.getUrl())
                .set("spark.redis.port", ""+credentials.getPort());
        RedisConfig redisConfig = RedisConfig.fromSparkConf(sparkConf);
        ReadWriteConfig readWriteConfig = ReadWriteConfig.fromSparkConf(sparkConf);
		//        JavaSparkContext jsc = new JavaSparkContext(sparkConf);
        JavaSparkContext jsc = JavaSparkContext.fromSparkContext(getSession().sparkContext());
        RedisContext redisContext = new RedisContext(jsc.sc());

        // Get key value pairs non specific type of values.
        // Convert RDD to Dataset<Row>
        RDD<Tuple2<String, String>> rdd = redisContext.fromRedisKV(keypattern, 1, redisConfig, readWriteConfig);
        JavaRDD<Tuple2<String, String>> javaRDD = rdd.toJavaRDD();
        JavaRDD<Row> rowRDD = javaRDD.map((Function<Tuple2<String, String>, Row>) record -> {
            String key = record._1;
            String value = record._2;
            return RowFactory.create(key, value);
        });
		SparkSession spark = SparkSession.builder().config(sparkConf).getOrCreate();
        StructType schema = DataTypes.createStructType(Arrays.asList(DataTypes.createStructField("key",DataTypes.StringType,true), DataTypes.createStructField("value",DataTypes.StringType,true)));
        Dataset<Row> res = spark.createDataFrame(rowRDD, schema);
		return res;
		[else]
		Jedis jedis;
		jedis = new Jedis(credentials.getUrl(), credentials.getPort());
		ScanParams scanParams = new ScanParams().match(keypattern).count(100);
		String cur = ScanParams.SCAN_POINTER_START;
		boolean cycleIsFinished = false;
		List<String> keys = new ArrayList<String>();
		Dataset<Row> res = new Dataset<Row>();
		while(!cycleIsFinished) {
			ScanResult<String> scanResult =
					jedis.scan(cur, scanParams);
			keys.addAll(scanResult.getResult());

			cur = scanResult.getCursor();
			if (cur.equals("0")) {
				cycleIsFinished = true;
			}
		}
		if(keys.isEmpty())
			return null;
		List<String> values = jedis.mget(keys.toArray(new String['['/]keys.size()[']'/]));
		
		for (int i = 0; i < keys.size(); i++) {
				String key = keys.get(i);
				countInKey = StringUtils.countMatches(key,':');
				if(countInKey <= countInKeyPattern){
					Map<String, Object> map = new HashMap<String, Object>();
					String value = values.get(i);
					if(value != null) {
						map.put("key", key);
						map.put("value", value);
						res.add(new Row(map));
					}
				}else{
					logger.warn("Possible overlapping key retrieved. Key ['['/]{}[']'/], Keypattern ['['/]{}[']'/]. Skipping...", key,keypattern);
				}
		}

		jedis.close();
		return res;
		[/if]
	}

	public static Dataset<Row> getRowsFromKeyValueHashes(String dbName, String keypattern, StructType structTypeHash){
		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		logger.debug("Get keypattern (hash value) ['['/]{}[']'/] from redis db ['['/]{}[']'/]", keypattern, dbName);
		[if (isSparkConfiguration())]
		getSession().sparkContext().conf().set("spark.redis.host", credentials.getUrl());
		getSession().sparkContext().conf().set("spark.redis.port", ""+credentials.getPort());
		Dataset<Row> res = getSession().read().format("org.apache.spark.sql.redis")
                .option("keys.pattern",keypattern)
				.option("key.column", "_id")
                .schema(structTypeHash).load();
		return res;
		[else]
		Jedis jedis;
		jedis = new Jedis(credentials.getUrl(), credentials.getPort());
		ScanParams scanParams = new ScanParams().match(keypattern).count(100);
		String cur = ScanParams.SCAN_POINTER_START;
		boolean cycleIsFinished = false;
		Dataset<Row> res = new Dataset<Row>();
		while(!cycleIsFinished) {
			ScanResult<String> scanResult =
					jedis.scan(cur, scanParams);
			List<String> keysList = scanResult.getResult();

			for (String key : keysList) {
				try {
					Map map = jedis.hgetAll(key);
					map.put("_id", key);
					res.add(new Row(map));
				}catch(JedisDataException e)
				{
					logger.warn("Wrong type value for key ['['/]{}[']'/]. Key pattern asked ['['/]{}[']'/]. This indicates that other key value pairs not mentioned in the schema are in the database and in conflict. Continuing...", key, keypattern);
					//e.printStackTrace();
				}
			}
			cur = scanResult.getCursor();
			if (cur.equals("0")) {
				cycleIsFinished = true;
			}
		}
		jedis.close();
		return res;
		[/if]
	}

	public static Dataset<Row> getRowsFromKeyValueList(String dbName, String keypattern, StructType structType){
		DBCredentials credentials = DBCredentials.getDbPorts().get(dbName);
		logger.debug("Get keypattern (list value) ['['/]{}[']'/] from redis db ['['/]{}[']'/]", keypattern, dbName);
		[if (isSparkConfiguration())]
		List<Row> rows = new ArrayList<>();
		Jedis jedis;
		jedis = new Jedis(credentials.getUrl(), credentials.getPort());
		ScanParams scanParams = new ScanParams().match(keypattern).count(100);
		String cur = ScanParams.SCAN_POINTER_START;
		boolean cycleIsFinished = false;
		Map<String, List<String>> listKV = new HashMap<>();
		while(!cycleIsFinished) {
			ScanResult<String> scanResult =
					jedis.scan(cur, scanParams);
			List<String> keysList = scanResult.getResult();

			//do whatever with the key-value pairs in result
			for (String key : keysList) {
				try{
					List<String> listvalues = jedis.lrange(key, 0, -1);
					listKV.put(key, listvalues);
				}catch(JedisDataException e)
				{
					logger.warn("Wrong type value for key ['['/]{}[']'/]. Key pattern asked ['['/]{}[']'/]. This indicates that other key value pairs not mentioned in the schema are in the database and in conflict. Continuing...", key, keypattern);
					//e.printStackTrace();
				}
			}
			cur = scanResult.getCursor();
			if (cur.equals("0")) {
				cycleIsFinished = true;
			}
		}
		listKV.forEach((k,v) -> rows.add(RowFactory.create(k,v)));
		Dataset<Row> data = getSession().createDataFrame(rows, structType);
		jedis.close();
		return data;
		[else]
		Dataset<Row> rows = new Dataset<>();
		Jedis jedis;
		jedis = new Jedis(credentials.getUrl(), credentials.getPort());
		ScanParams scanParams = new ScanParams().match(keypattern).count(100);
		String cur = ScanParams.SCAN_POINTER_START;
		boolean cycleIsFinished = false;
		Map<String, List<String>> listKV = new HashMap<>();
		while(!cycleIsFinished) {
			ScanResult<String> scanResult =
					jedis.scan(cur, scanParams);
			List<String> keysList = scanResult.getResult();

			//do whatever with the key-value pairs in result
			for (String key : keysList) {
				try{
					List<String> listvalues = jedis.lrange(key, 0, -1);
					listKV.put(key, listvalues);
				}catch(JedisDataException e)
				{
					logger.warn("Wrong type value for key ['['/]{}[']'/]. Key pattern asked ['['/]{}[']'/]. This indicates that other key value pairs not mentioned in the schema are in the database and in conflict. Continuing...", key, keypattern);
					e.printStackTrace();
				}
			}
			cur = scanResult.getCursor();
			if (cur.equals("0")) {
				cycleIsFinished = true;
			}
		}
		String listFieldName = structType.fieldNames()['['/]1[']'/];
		listKV.forEach((k,v) -> {
			Map<String, Object> map = new HashMap<String, Object>();
			map.put("_id", k);
			map.put(listFieldName, v);
			rows.add(new Row(map));
		});
		jedis.close();
		return rows;
		[/if]
	} 
}
[/file]
[/template]

[template public generateDBCredentials(conceptualSchema: ConceptualSchema)]
[file ('src/main/java/dbconnection/DBCredentials.java', false, 'UTF-8')]
package dbconnection;

import java.util.HashMap;
import java.util.Map;


public class DBCredentials {
    private String dbName;
    private String url;
    private int port;
    private String userName;
    private String userPwd;
    private String dbType;
	private static Map<String, DBCredentials> dbPorts = new HashMap<String, DBCredentials>();

    protected DBCredentials(String dbName, String url, int port, String userName, String userPwd, String dbType) {
        this.dbName = dbName;
        this.url = url;
        this.port = port;
        this.userName = userName;
        this.userPwd = userPwd;
        this.dbType = dbType;
    }
	
	static {
		[for (db : Database | conceptualSchema.ancestors(Domainmodel)->first().databases.databases)]
			dbPorts.put("[db.name /]", new DBCredentials("[db.databaseName /]", "[db.host /]", [db.port /], "[db.login /]", "[db.password /]","[db.dbType/]"));
		[/for]
	}

	public static Map<String, DBCredentials> getDbPorts() {
        return dbPorts;
    }


    public String getDbName() {
        return dbName;
    }

    public String getUrl() {
        return url;
    }

    public int getPort() {
        return port;
    }

    public String getUserName() {
        return userName;
    }

    public String getUserPwd() {
        return userPwd;
    }

    public String getDbType() {
        return dbType;
    }

    public String getDbTypeForJDBCConnection() {
	    switch (dbType) {
            case "mysql":
            case "mariadb":
                return "mysql";
            default:
                return dbType;
        }
    }

}

[/file]
[/template]

[template public generateRelationalDBConnectionClasses(conceptualSchema: ConceptualSchema)]
[file ('src/main/java/dbconnection/RelationalDBConnection.java', false, 'UTF-8')]
package dbconnection;

import java.sql.SQLException;

public class RelationalDBConnection implements DBConnection{
	[instantiateLogger('RelationalDBConnection') /]
	protected String host;
	protected String port;
	protected String driverClass;
	protected String schemaName;
	protected String userName;
	protected String userPassword;
	protected String dbType;

	protected String jdbcUrl;

	private java.sql.Connection conn = null;

	public RelationalDBConnection(String host, String port, String dbType, String schemaName, String userName, String userPassword)
			throws ClassNotFoundException, java.sql.SQLException {
		this.host = host;
		this.port = port;
		this.schemaName = schemaName;
		this.userName = userName;
		this.userPassword = userPassword;
		this.dbType = dbType;
		this.jdbcUrl = "jdbc:"+dbType+"://" + this.host + ":" + this.port + "/" + this.schemaName;
		this.driverClass = "com.mysql.jdbc.Driver";

		//Class.forName(this.driverClass);
		openConnection();
	}

	public void openConnection(){
		if(this.conn == null)
			try{
			logger.debug("Opening relational DB connection {}", jdbcUrl);
			this.conn = java.sql.DriverManager.getConnection(this.jdbcUrl, this.userName, this.userPassword);
			}catch(SQLException e){
				logger.error("Impossible to connect to DB {}", jdbcUrl);
				System.err.println(e);
				System.exit(1);
			}
	}

	public void closeConnection() {
		try {
			if(conn != null)
				conn.close();
		}catch(SQLException e){
				logger.error("Impossible to close DB connection{}", jdbcUrl);
				System.err.println(e);
			} finally {
			conn = null;
		}
	}

	public java.sql.ResultSet select(String query) throws java.sql.SQLException {
		return select(query, null);
	}

	public java.sql.ResultSet select(String query, java.util.List<Object> inputs) throws java.sql.SQLException {
		openConnection();
		java.sql.PreparedStatement st = null;
		try {
			st = conn.prepareStatement(query);
			int i = 1;
			if (inputs != null)
				for (Object input : inputs) {
					st.setObject(i, input);
					i++;
				}

			return st.executeQuery();
		} catch (java.sql.SQLException e) {
			if (st != null)
				st.close();
			throw e;
		}
	}

	public void closeStatement(java.sql.ResultSet r) throws java.sql.SQLException {
		if (r != null) {
			java.sql.Statement st = r.getStatement();
			if (st != null)
				st.close();
		}
	}

	@Override
	public int insertOrUpdateOrDelete(String query, java.util.List<Object> inputs) {
		java.sql.PreparedStatement st = null;
		try {
			openConnection();
			logger.debug("Executing insert/update/delete statement [ '['/]{}[ ']'/]",query);
			st = conn.prepareStatement(query);
			int i = 1;
			if (inputs != null)
				for (Object input : inputs) {
					st.setObject(i, input);
					i++;
				}

			return st.executeUpdate();
		}catch(SQLException e){
			logger.error("Error executing insert/update/delete statement");
			System.err.println(e);
			System.exit(1);
		} finally {
			if (st != null)
			try{
				st.close();
			}catch(SQLException e){
				logger.error("Impossible to close statement");
				System.err.println(e);
			}
		}
		return 0;
	}

	public int insertOrUpdateOrDelete(String query) throws java.sql.SQLException {
		return insertOrUpdateOrDelete(query, null);
	}

}

[/file]
[/template]

[template public generateDocumentDBConnectionClasses(conceptualSchema: ConceptualSchema)]
[file ('src/main/java/dbconnection/DocumentDBConnection.java', false, 'UTF-8')]
package dbconnection;

public class DocumentDBConnection {
	protected String host;
	protected String port;
	protected String dbName;
	protected String userName;
	protected String userPassword;

	protected String mongoUrl;
	protected com.mongodb.MongoClient mongoClient = null;
	protected com.mongodb.client.MongoDatabase db = null;

	public DocumentDBConnection(String host, String port, String dbName, String userName, String userPassword) throws java.sql.SQLException {
		this.host = host;
		this.port = port;
		this.dbName = dbName;
		this.userName = userName;
		this.userPassword = userPassword;

		this.mongoUrl = "mongodb://" + userName + ":" + userPassword + "@" + host + ":" + port;
		openConnection();
	}

	public void openConnection() throws java.sql.SQLException {
		if (this.db == null) {
			com.mongodb.MongoClientURI uri = new com.mongodb.MongoClientURI(mongoUrl);
			mongoClient = new com.mongodb.MongoClient(uri);
			db = mongoClient.getDatabase(dbName);
		}
	}

	public void closeConnection() {
		try {
			if (mongoClient != null)
				mongoClient.close();

		} finally {
			this.db = null;
		}
	}

}
[/file]
[/template]

[template public generateKeyValueDBConnectionClasses(conceptualSchema: ConceptualSchema)]
[file ('src/main/java/dbconnection/KeyValueDBConnection.java', false, 'UTF-8')]
package dbconnection;

public class KeyValueDBConnection {
	
	protected String host;
	protected int port;
	protected String userPassword;
	
	protected redis.clients.jedis.Jedis conn = null;
	
	public KeyValueDBConnection(String host, int port, String userPassword) {
		this.host = host;
		this.port = port;
		this.userPassword = userPassword;
		openConnection();
	}
	
	public void openConnection() {
		if(conn == null) {
			conn = new redis.clients.jedis.Jedis(host, port);
			conn.auth(userPassword);//password
		}
	}

	public void closeConnection() {
		if(conn != null) {
			conn.close();
		}
	}
	
}

[/file]
[/template]

[template public generateColumnDBConnectionClasses(conceptualSchema: ConceptualSchema)]
[file ('src/main/java/dbconnection/ColumnDBConnection.java', false, 'UTF-8')]
package dbconnection;

public class ColumnDBConnection {
	protected String host;
	protected int port;
	protected String userPassword;
	protected String userName;
	protected String keyspaceName;

	private com.datastax.oss.driver.api.core.CqlSession session = null;

	public ColumnDBConnection(String host, int port, String keyspaceName, String userName, String userPassword) {
		this.host = host;
		this.port = port;
		this.userName = userName;
		this.userPassword = userPassword;
		this.keyspaceName = keyspaceName;
		openConnection();
	}

	public void openConnection() {
		if (session == null)
			session = com.datastax.oss.driver.api.core.CqlSession.builder()
					// make sure you change the path to the secure connect bundle below
					// .withCloudSecureConnectBundle(Paths.get("/path/to/secure-connect-database_name.zip"))
					.withAuthCredentials(this.userName, this.userPassword).withKeyspace(this.keyspaceName).build();
	}

	public void closeConnection() {
		if (session != null)
			session.close();
	}
	

	public com.datastax.oss.driver.api.core.cql.ResultSet executeQuery(String query, java.util.List<Object> inputs) {
		openConnection();
		// ResultSet rs = session.execute("select release_version from system.local");
		com.datastax.oss.driver.api.core.cql.PreparedStatement prepared = session.prepare(query);
		com.datastax.oss.driver.api.core.cql.BoundStatement bound;
		if (inputs == null || inputs.size() == 0)
			bound = prepared.bind();
		else
			bound = prepared.bind(inputs);
		
		return session.execute(bound);
	}

	public com.datastax.oss.driver.api.core.cql.ResultSet select(String query, java.util.List<Object> inputs) {
		return executeQuery(query, inputs);
	}
	
	public com.datastax.oss.driver.api.core.cql.ResultSet select(String query) {
		return select(query, null);
	}
	
	public void insertOrUpdateOrDelete(String query, java.util.List<Object> inputs) {
		executeQuery(query, inputs);
	}
	
	public void insertOrUpdateOrDelete(String query) {
		insertOrUpdateOrDelete(query, null);
	}
}

[/file]
[/template]

[template public generateGraphDBConnectionClasses(conceptualSchema: ConceptualSchema)]
[file ('src/main/java/dbconnection/GraphDBConnection.java', false, 'UTF-8')]
package dbconnection;

public class GraphDBConnection {

	protected String host;
	protected int port;
	protected String userName;
	protected String userPassword;
	
	private String neo4jUrl;

	protected org.neo4j.driver.Driver driver;
	protected org.neo4j.driver.Session session;

	public GraphDBConnection(String host, int port, String userName, String userPassword) {
		this.host = host;
		this.port = port;
		this.userName = userName;
		this.userPassword = userPassword;
		
		// it can exist different ways to connect a Neo4j db (see https://neo4j.com/developer/java/)
		this.neo4jUrl = "neo4j://" + this.host + ":" + this.port;
		openConnection();
	}

	public void openConnection() {
		if (driver == null) {
			driver = org.neo4j.driver.GraphDatabase.driver(this.neo4jUrl,
					org.neo4j.driver.AuthTokens.basic(this.userName, this.userPassword));
			session = driver.session();
		}
	}

	public void closeConnection() {
		if (driver != null) {
			session.close();
			driver.close();
		}
	}
	
	public org.neo4j.driver.Result select(String cypher) {
		return select(cypher, new java.util.HashMap<String, Object>());
	}
	
	public org.neo4j.driver.Result select(String cypher, java.util.Map<String,Object> parameters) {
		openConnection();
		return session.run(cypher, parameters);
	}
	
	public void insertOrUpdateorDelete(String cypher) {
		insertOrUpdateorDelete(cypher, new java.util.HashMap<String, Object>());
	}
	
	public void insertOrUpdateorDelete(String cypher, java.util.Map<String,Object> parameters) {
		openConnection();
		session.run(cypher, parameters);
	}

}

[/file]
[/template]

[template private generateDatabaseTypeConverters()]

[file ('src/main/java/util/DBTypeConverter.java', false, 'UTF-8')]
package util;

import java.math.BigDecimal;
import java.math.BigInteger;
import java.sql.Blob;
import java.sql.Date;
import java.sql.SQLException;
import java.sql.Time;
import java.sql.Timestamp;
import java.time.Instant;
import java.time.LocalDate;
import java.time.LocalDateTime;
import java.time.LocalTime;
import java.time.ZoneId;
import java.time.format.DateTimeFormatter;
import java.time.format.DateTimeParseException;
import java.util.UUID;

import javax.sql.rowset.serial.SerialBlob;

public class DBTypeConverter {
	
	protected static String getString(Object o) {
		return o.toString();
	}

	protected static Short getShort(Object o) {
		if(o instanceof Short)
			return (Short) o;
		if (o instanceof Integer)
			return ((Integer) o).shortValue();
		if (o instanceof Long)
			return ((Long) o).shortValue();
		if (o instanceof Boolean)
			return (boolean) o ? (short) 1 : (short) 0;
		if (o instanceof Float)
			return ((Float) o).shortValue();
		if (o instanceof Double)
			return ((Double) o).shortValue();

		try {
			return Short.parseShort(o.toString());
		} catch (NumberFormatException e) {
			return null;
		}

	}

	protected static UUID getUUID(Object o) {
		try {
			return UUID.fromString(o.toString());
		} catch (IllegalArgumentException e) {
			return null;
		}
	}

	protected static Integer getInteger(Object o) {
		if (o instanceof Integer)
			return ((Integer) o);
		if (o instanceof Short)
			return ((Short) o).intValue();
		if (o instanceof Long)
			return ((Long) o).intValue();
		if (o instanceof Boolean)
			return (boolean) o ? 1 : 0;
		if (o instanceof Float)
			return ((Float) o).intValue();
		if (o instanceof Double)
			return ((Double) o).intValue();

		try {
			return Integer.parseInt(o.toString());
		} catch (NumberFormatException e) {
			return null;
		}
	}
	
	protected static Long getLong(Object o) {
		if(o instanceof Long)
			return (Long) o;
		if (o instanceof Integer)
			return ((Integer) o).longValue();
		if (o instanceof Short)
			return ((Short) o).longValue();
		if (o instanceof Long)
			return ((Long) o).longValue();
		if (o instanceof Boolean)
			return (boolean) o ? 1L : 0L;
		if (o instanceof Float)
			return ((Float) o).longValue();
		if (o instanceof Double)
			return ((Double) o).longValue();

		try {
			return Long.parseLong(o.toString());
		} catch (NumberFormatException e) {
			return null;
		}
	}

	protected static LocalTime getLocalTime(Object o) {
		//TODO pml::LocalTime is missing
		return null;
	}

	protected static Instant getInstant(Object o) {
		if(o instanceof LocalDateTime) // yyyy-mm-dd['['/](T| )HH:MM:SS['['/].fff[']'/][']'/]['['/](+|-)NNNN[']'/]
			return ((LocalDateTime) o).atZone(ZoneId.systemDefault()).toInstant();
		
		if(o instanceof LocalDate) // yyyy-mm-dd
			return ((LocalDate) o).atStartOfDay().atZone(ZoneId.systemDefault()).toInstant();
		
		try {
			return LocalDateTime.parse(o.toString(), DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss.SSS")).atZone(ZoneId.systemDefault()).toInstant();
		} catch(DateTimeParseException e) {
			return null;
		}
		
	}
	
	protected static LocalDateTime getLocalDateTime(Object o) {
		if(o instanceof LocalDateTime) // yyyy-mm-dd['['/](T| )HH:MM:SS['['/].fff[']'/][']'/]['['/](+|-)NNNN[']'/]
			return (LocalDateTime) o;
		
		if(o instanceof LocalDate) // yyyy-mm-dd
			return ((LocalDate) o).atStartOfDay();
		
		try {
			return LocalDateTime.parse(o.toString(), DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss.SSS"));
		} catch(DateTimeParseException e) {
			return null;
		}
		
	}
	
	protected static Date getDate(Object o) {
		if(o instanceof LocalDate) // yyyy-mm-dd
			return Date.valueOf((LocalDate) o);
		
		if(o instanceof LocalDateTime) // yyyy-mm-dd['['/](T| )HH:MM:SS['['/].fff[']'/][']'/]['['/](+|-)NNNN[']'/]
			return Date.valueOf(((LocalDateTime) o).toLocalDate());
		
		try {
			return Date.valueOf(LocalDate.parse(o.toString(), DateTimeFormatter.ofPattern("yyyy-MM-dd")));
		} catch(DateTimeParseException e) {
			return null;
		}
	}
	
	protected static Time getTime(Object o) {
		//TODO pml::LocalTime is missing
		return null;
	}
	
	protected static Timestamp getTimestamp(Object o) {
		if(o instanceof LocalDate) // yyyy-mm-dd
			return Timestamp.valueOf(((LocalDate) o).atStartOfDay());
		
		if(o instanceof LocalDateTime) // yyyy-mm-dd['['/](T| )HH:MM:SS['['/].fff[']'/][']'/]['['/](+|-)NNNN[']'/]
			return Timestamp.valueOf((LocalDateTime) o);
		
		try {
			return Timestamp.valueOf(LocalDateTime.parse(o.toString(), DateTimeFormatter.ofPattern("yyyy-MM-dd HH:mm:ss")));
		} catch(DateTimeParseException e) {
			return null;
		}
	}

	protected static LocalDate getLocalDate(Object o) {
		if(o instanceof LocalDate) // yyyy-mm-dd
			return (LocalDate) o;
		
		if(o instanceof LocalDateTime) // yyyy-mm-dd['['/](T| )HH:MM:SS['['/].fff[']'/][']'/]['['/](+|-)NNNN[']'/]
			return ((LocalDateTime) o).toLocalDate();
		
		try {
			return LocalDate.parse(o.toString(), DateTimeFormatter.ofPattern("yyyy-MM-dd"));
		} catch(DateTimeParseException e) {
			return null;
		}
	}

	protected static Float getFloat(Object o) {
		if (o instanceof Float)
			return ((Float) o);
		if (o instanceof Integer)
			return ((Integer) o).floatValue();
		if (o instanceof Short)
			return ((Short) o).floatValue();
		if (o instanceof Long)
			return ((Long) o).floatValue();
		if (o instanceof Boolean)
			return (boolean) o ? 1f : 0f;
		if (o instanceof Double)
			return ((Double) o).floatValue();

		try {
			return Float.parseFloat(o.toString());
		} catch (NumberFormatException e) {
			return null;
		}
	}

	protected static Double getDouble(Object o) {
		if (o instanceof Float)
			return ((Float) o).doubleValue();
		if (o instanceof Integer)
			return ((Integer) o).doubleValue();
		if (o instanceof Short)
			return ((Short) o).doubleValue();
		if (o instanceof Long)
			return ((Long) o).doubleValue();
		if (o instanceof Boolean)
			return (boolean) o ? 1d : 0d;
		if (o instanceof Double)
			return ((Double) o);

		try {
			return Double.parseDouble(o.toString());
		} catch (NumberFormatException e) {
			return null;
		}
	}

	protected static Byte getByte(Object o) {
		// TODO Auto-generated method stub
		return null;
	}

	protected static Boolean getBoolean(Object o) {
		if(o instanceof Boolean)
			return (Boolean) o;
		
		if(o instanceof String)
			return o.equals("true") || o.equals("1");
		
		if (o instanceof Integer)
			return ((Integer) o) == 1;
		if (o instanceof Short)
			return ((Short) o).intValue() == 1;
		if (o instanceof Long)
			return  ((Long) o).intValue() == 1;
		if (o instanceof Float)
			return  ((Float) o).intValue() == 1;
		if (o instanceof Double)
			return  ((Double) o).intValue() == 1;

		return null;
	}
	

	protected static BigInteger getBigInteger(Object o) {
		if (o instanceof Integer)
			return BigInteger.valueOf((Integer) o);
		if (o instanceof Short)
			return BigInteger.valueOf(((Short) o));
		if (o instanceof Long)
			return  BigInteger.valueOf((Long) o);
		if (o instanceof Boolean)
			return  BigInteger.valueOf((boolean) o ? 1 : 0);
		if (o instanceof Float)
			return  BigInteger.valueOf(((Float) o).intValue());
		if (o instanceof Double)
			return  BigInteger.valueOf(((Double) o).intValue());

		try {
			return BigInteger.valueOf(Integer.parseInt(o.toString()));
		} catch (NumberFormatException e) {
			return null;
		}
	}

	protected static BigDecimal getBigDecimal(Object o) {
		if (o instanceof Integer)
			return new BigDecimal((Integer) o);
		if (o instanceof Short)
			return new BigDecimal(((Short) o));
		if (o instanceof Long)
			return  new BigDecimal((Long) o);
		if (o instanceof Boolean)
			return  new BigDecimal((boolean) o ? 1 : 0);
		if (o instanceof Float)
			return  new BigDecimal(((Float) o).intValue());
		if (o instanceof Double)
			return  new BigDecimal(((Double) o).intValue());

		try {
			return new BigDecimal(o.toString());
		} catch (NumberFormatException e) {
			return null;
		}
	}
	

	protected static Blob getBlob(Object o) {
		try {
			return new SerialBlob(o.toString().getBytes());
		} catch (SQLException e) {
			e.printStackTrace();
			return null;
		}
	}

}

[/file]

[file ('src/main/java/util/CassandraTypeConverter.java', false, 'UTF-8')]
package util;

import java.math.BigDecimal;
import java.math.BigInteger;
import java.time.Instant;
import java.time.LocalDate;
import java.time.LocalTime;
import java.util.UUID;

import com.datastax.oss.driver.api.core.type.DataType;
import com.datastax.oss.driver.api.core.type.DataTypes;

public class CassandraTypeConverter extends DBTypeConverter {

	public static Object get(Object o, DataType type) {
		if (o == null || type == null)
			return null;

		if (type.equals(DataTypes.DECIMAL))
			return (BigDecimal) getBigDecimal(o);
		if (type.equals(DataTypes.BIGINT))
			return (BigInteger) getBigInteger(o);
		if (type.equals(DataTypes.BOOLEAN))
			return (Boolean) getBoolean(o);
		if (type.equals(DataTypes.BLOB))
			return (Byte) getByte(o);
		if (type.equals(DataTypes.DOUBLE))
			return (Double) getDouble(o);
		if (type.equals(DataTypes.FLOAT))
			return (Float) getFloat(o);
		if (type.equals(DataTypes.DATE)) // yyyy-mm-dd
			return (LocalDate) getLocalDate(o);
//		if (type.equals(DataTypes.DURATION))
//			return (Instant) getInstant(o);
		if (type.equals(DataTypes.TIMESTAMP)) // yyyy-mm-dd['['/](T| )HH:MM:SS['['/].fff[']'/][']'/]['['/](+|-)NNNN[']'/]
			return (Instant) getInstant(o);
		if (type.equals(DataTypes.TIME)) // HH:MM:SS['['/].fff[']'/]
			return (LocalTime) getLocalTime(o);
		if (type.equals(DataTypes.SMALLINT))
			return (Integer) getInteger(o);
		if (type.equals(DataTypes.UUID))
			return (UUID) getUUID(o);
		if (type.equals(DataTypes.INT))
			return (Integer) getInteger(o);
		if (type.equals(DataTypes.TINYINT))
			return (Short) getShort(o);
		if (type.equals(DataTypes.TEXT))
			return (String) getString(o);
		// java.math.BigDecimal
		// java.math.BigInteger
		// boolean
		// byte
		// double
		// float
		// java.time.Instant
		// int
		// List
		// java.time.LocalDate
		// java.time.LocalTime
		// long
		// Map
		// Set
		// short
		// String
		// java.util.UUID
		return null;
	}

	

}

[/file]

[file ('src/main/java/util/SQLTypeConverter.java', false, 'UTF-8')]
package util;

import java.math.BigDecimal;
import java.sql.Blob;
import java.sql.Date;
import java.sql.Time;
import java.sql.Timestamp;

public class SQLTypeConverter extends DBTypeConverter {
	
	
	public static Object get(Object o, String className) {
		if (o == null || className == null)
			return null;
		
		
		if(className.equals("java.lang.String"))
			return (String) getString(o);
		if(className.equals("java.lang.Integer"))
			return (Integer) getInteger(o);
		if(className.equals("java.lang.Float"))
			return (Float) getFloat(o);
		if(className.equals("java.sql.Date"))
			return (Date) getDate(o);
		if(className.equals("java.sql.Timestamp"))
			return (Timestamp) getTimestamp(o);
		if(className.equals("java.sql.Time"))
			return (Time) getTime(o);
		if(className.equals("java.math.BigDecimal"))
			return (BigDecimal) getBigDecimal(o);
		if(className.equals("java.lang.Boolean"))
			return (Boolean) getBoolean(o);
		if(className.equals("java.lang.Double"))
			return (Double) getDouble(o);
		if(className.equals("java.lang.Long"))
			return (Long) getLong(o);
		if(className.equals("java.sql.Blob") || className.equals("['['/]B"))
			return (Blob) getBlob(o);
		
//		java.lang.Byte
//		java.sql.Clob
//		java.sql.NClob
		
		return null;
	}

}

[/file]
[/template]